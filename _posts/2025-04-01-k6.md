---
layout: post
title:  "k6를 통한 성능 테스트"
---

처음 백엔드를 공부할 떄는 성능을 고려하기보단 단순히 기능을 구현하기에 바빴다. <br>
n+1 문제나 반정규화를 통한 성능개선, 캐시를 통한 쿼리 감소 등 백엔드 서버 성능 개선을 위한 방법은 이론으로는 알고 있었지만 실제로 해본적은 없었다. <br>
하지만 이번 캡스톤 프로젝트는 시간이 된다면 기능 완성 후에 위와 같은 성능 개선을 시도해보려고 한다.(시간이 없다면 제출 후에라도 할 생각이다.) <br>
그런데 정작 성능 개선을 할 생각을 하니 "성능이 개선된 것을 어떻게 확인하지?" 라는 생각이 들었고, 검색을 해보니 k6를 통해서 부하테스트를 하고, grafana를 통해 시각화를 하는 방법이 유명했다.
그래서 성능 측정에 앞서 내 웹서버에 부하를 주는 k6를 사용해보고자 한다.

k6를 설치하고 "k6 new" 명령어를 cmd에서 실행하면 k6 공식 예제 파일이 생성된다.<br>

![image](https://github.com/user-attachments/assets/4b52d87a-7ce5-4ec1-aed2-83718ea0d52e)
<br>

k6 run script.js 다음 명령어를 입력하면 성능테스트가 실행되고 다음과 같은 결과가 나온다.<br>
![image](https://github.com/user-attachments/assets/3df9b345-1dc3-4446-8221-1a04be9074aa)
<br>

### 1. 데이터 관련 지표
data_received: 테스트 중 수신된 총 데이터(바이트)

data_sent: 테스트 중 전송된 총 데이터(바이트)

### 2. HTTP 요청 관련 지표
http_req_blocked: 요청이 네트워크 또는 k6 내부 큐에서 차단된 시간(대기 시간 포함)

http_req_connecting: HTTP 연결을 설정하는 데 걸린 시간 (Keep-Alive가 활성화된 경우 0일 수 있음)

http_req_duration: 전체 HTTP 요청 시간 (DNS 조회, TCP 연결, TLS 핸드셰이크, 요청 전송, 서버 처리, 응답 수신 포함)

{ expected_response:true }: 예상한 응답을 받은 요청만 필터링할 때 사용

http_req_failed: 실패한 HTTP 요청의 비율 (0이면 모든 요청이 성공)

http_req_receiving: 응답 데이터를 수신하는 데 걸린 시간

http_req_sending: 요청 데이터를 전송하는 데 걸린 시간

http_req_tls_handshaking: TLS 핸드셰이크(SSL 연결)를 수행하는 데 걸린 시간

http_req_waiting: 요청을 보낸 후 서버가 응답을 시작할 때까지 걸린 시간 (서버 처리 시간)

http_reqs: 실행된 총 HTTP 요청 수

### 3. 실행 및 부하 관련 지표
iteration_duration: 단일 시뮬레이션 반복(iteration) 수행에 걸린 시간 (setup, teardown 포함)

iterations: 완료된 총 반복(iteration) 수

vus: 현재 실행 중인 Virtual Users(VUs, 가상 사용자) 수

vus_max: 테스트 실행 중의 최대 VUs 수


### 내 서버로 테스트해보기
이번엔 k6가 제공하는 주소 대신 내 로컬 웹서버의 경로로 요청을 보내서 테스트를 해봤다.
vu를 10배 늘리면 10배 느려질까? 라는 궁금증이 생겨서 몇가지 테스트를 돌려봤다.
기본(10)
![image](https://github.com/user-attachments/assets/7af5ed0e-7034-4329-aa59-87da3a31627d)
10배(100)
![image](https://github.com/user-attachments/assets/70e17558-c34c-45ff-b4be-b4b30343e505)
100배(1000)
![image](https://github.com/user-attachments/assets/2cdea327-5a6f-4301-bc01-502ba46ae717)
vu가 1000이 넘어가니까 에러가 발생했다.

gpt에게 물어보니 보통 다음과 같은 이유때문에 에러가 발생한다고 한다.

1️⃣ 서버의 최대 동시 연결 수 제한

대부분의 웹 서버(예: Nginx, Apache, Node.js)는 동시 연결 수에 제한이 있음.

기본 설정에서는 100~500개 정도의 동시 연결을 허용하는 경우가 많아.

동시 요청이 서버의 최대 한도를 초과하면 연결이 거부될 수 있음.

2️⃣ 시스템 리소스 부족 (CPU, 메모리, 네트워크)

vus: 1000이면, k6는 **1000개의 가상 사용자(VU)**가 동시 요청을 보냄.

서버가 충분한 CPU, RAM, 네트워크 대역폭을 가지고 있지 않다면 요청을 처리하지 못하고 연결을 끊어버릴 수 있음.

서버의 리소스 사용량 확인 (top, htop, Task Manager, Activity Monitor)

3️⃣ 서버의 TCP 연결 제한

OS나 서버의 네트워크 스택이 너무 많은 연결을 동시에 허용하지 못하는 경우가 있음.

리눅스의 경우 ulimit -n 명령어로 최대 파일(소켓 포함) 개수를 확인할 수 있음.

기본적으로 많은 운영체제에서 1024~4096 정도의 제한이 걸려 있음.

sysctl을 이용해 커널의 TCP 연결 한계를 증가시켜야 할 수도 있음.

4️⃣ 데이터베이스의 연결 제한

만약 테스트 중에 API가 DB와 통신하고 있다면, DB 연결 수 제한(max_connections)을 초과했을 가능성도 있음.

MySQL, PostgreSQL 등의 DB는 기본적으로 최대 동시 연결 수를 제한함.

DB 연결 풀 크기를 늘려야 할 수도 있음.

5️⃣ 서버의 Keep-Alive 설정 문제

일부 서버는 너무 많은 Keep-Alive 연결을 유지하려고 하다가 연결을 끊어버릴 수 있음.

Nginx 같은 경우 worker_connections, keepalive_timeout 설정을 조정해야 할 수도 있음.

데이터베이스를 사용하지 않았고, keep-alive는 꺼뒀기 때문에 1,2,3번 중 하나가 원인이라고 생각했고, 다음 코드처럼 vu를 처음부터 1000으로 설정하는 것이 아니라 서서히 올리니까 문제가 발생하지 않았다.

```javascript
import http from 'k6/http';
import { sleep } from 'k6';

export const options = {
  // A number specifying the number of VUs to run concurrently.
  // vus: 100,
  // // A string specifying the total duration of the test run.
  // duration: '30s',
  stages: [
    { duration: '30s', target: 100 },  // 30초 동안 100 VUs로 증가
    { duration: '1m', target: 500 },   // 1분 동안 500 VUs 유지
    { duration: '30s', target: 1000 }, // 30초 동안 1000 VUs까지 증가
    { duration: '1m', target: 1000 },  // 1분 동안 1000 VUs 유지
    { duration: '30s', target: 0 }     // 30초 동안 VUs를 0으로 감소
  ]
};
export default function() {
  http.get('http://localhost:8080/test');
  sleep(1);
}

```
수정한 코드는 vu가 동일하게 1000이더라도 서버가 부하에 적응할 시간이 있어서 터지지 않은 것 같다.

지금은 cli에서 테스트 결과를 볼 수 있는데 별로 가독성이 좋지 않은것 같다. 다음 글은 grafana를 연동해서 결과를 확인하는 것을 주제로 글을 올려야겠다.
얼른 성능 측정 환경을 구축하고 다양한 성능개선을 해보고 싶다.



